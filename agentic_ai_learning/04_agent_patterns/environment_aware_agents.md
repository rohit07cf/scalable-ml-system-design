# Environment-Aware Agents

## What It Is

- Agents that **perceive, adapt to, and act within their environment** in real-time
- They don't just process prompts ‚Äî they monitor conditions, react to changes, and maintain situational awareness
- Inspired by the **OODA loop** (Observe-Orient-Decide-Act) from military strategy
- Examples: monitoring agents, trading agents, DevOps agents, security agents

## Why It Matters (Interview Framing)

> "Environment-aware agents are the next evolution beyond task-based agents. Interviewers ask about them when discussing real-time systems, autonomous operations, and continuous monitoring. This shows you understand agents that live in the world, not just respond to prompts."

---

## Simple Mental Model

> A task-based agent is like a **freelancer** ‚Äî you give them a job, they do it, they're done.
> An environment-aware agent is like a **security guard** ‚Äî they're always watching, always ready to act when something changes.

---

## How They Differ from Task-Based Agents

| Dimension | Task-Based Agent | Environment-Aware Agent |
|---|---|---|
| **Trigger** | User request | Environmental change / event |
| **Lifecycle** | Start ‚Üí Execute ‚Üí End | Always running (daemon) |
| **Input** | Prompt from user | Sensor data, metrics, events, feeds |
| **Awareness** | Task context only | Full environmental state |
| **Adaptation** | None (fixed task) | Adjusts behavior based on conditions |
| **Example** | "Summarize this doc" | "Alert me if server latency > 500ms" |

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ENVIRONMENT-AWARE AGENT                   ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                    ‚îÇ
‚îÇ  ‚îÇ OBSERVE  ‚îÇ ‚Üê Sensors / APIs / Events          ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ   (metrics, logs, feeds, state)     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                    ‚îÇ
‚îÇ       ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                    ‚îÇ
‚îÇ  ‚îÇ  ORIENT  ‚îÇ ‚Üê Context + Memory + Rules         ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ   "Is this normal? What changed?"   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                    ‚îÇ
‚îÇ       ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                    ‚îÇ
‚îÇ  ‚îÇ  DECIDE  ‚îÇ ‚Üê Policy + LLM Reasoning           ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ   "What should I do about this?"    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                    ‚îÇ
‚îÇ       ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                    ‚îÇ
‚îÇ  ‚îÇ   ACT    ‚îÇ ‚Üê Tools / Actions / Alerts         ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ   (scale infra, alert team, fix)    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                    ‚îÇ
‚îÇ       ‚îÇ                                          ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ continuous loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## The OODA Loop in Detail

| Phase | What the Agent Does | Example (DevOps Agent) |
|---|---|---|
| **Observe** | Collect data from sensors, APIs, events | Read Prometheus metrics, check logs |
| **Orient** | Contextualize ‚Äî compare to baselines, history, rules | "Latency is 2x above 95th percentile for this time of day" |
| **Decide** | Choose action based on policy + reasoning | "This is likely a traffic spike. Scale up by 3 replicas." |
| **Act** | Execute the chosen action | `kubectl scale deployment --replicas=6` |

---

## Types of Environment-Aware Agents

### 1. Monitoring Agents

```
Metrics Stream ‚Üí [Agent] ‚Üí Detect Anomaly ‚Üí Alert / Action
```

- Watch infrastructure, application, or business metrics
- Detect anomalies, threshold breaches, trend changes
- Alert humans or take automated remediation actions

### 2. Trading / Financial Agents

```
Market Feed ‚Üí [Agent] ‚Üí Analyze ‚Üí Trade Decision ‚Üí Execute
```

- Monitor market data, news, social sentiment
- Make trading decisions based on strategy + conditions
- Extreme latency and safety requirements

### 3. Security Agents

```
Log Stream ‚Üí [Agent] ‚Üí Threat Detection ‚Üí Response
```

- Monitor security logs, network traffic, access patterns
- Detect suspicious activity, potential breaches
- Automated incident response (block IP, revoke token)

### 4. DevOps / SRE Agents

```
Infra State ‚Üí [Agent] ‚Üí Health Check ‚Üí Auto-remediate
```

- Monitor infrastructure health
- Auto-scale, restart services, rollback deployments
- Reduce mean time to recovery (MTTR)

---

## Key Design Considerations

| Consideration | Details |
|---|---|
| **Observation frequency** | How often to check (1s? 1min? 5min?) ‚Äî balance freshness vs cost |
| **State representation** | How to represent environment state for the LLM (structured vs natural language) |
| **Anomaly detection** | Statistical (threshold), ML-based (trained model), or LLM-based (reasoning) |
| **Action safety** | Automated actions must be reversible. Human approval for destructive actions. |
| **Feedback loops** | Agent's actions change the environment ‚Äî must account for this |
| **Cost** | Continuous LLM calls are expensive. Use rule-based pre-filters. |

---

## Hybrid Architecture (Recommended)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Rule Engine (fast, cheap)                       ‚îÇ
‚îÇ  - Threshold checks                             ‚îÇ
‚îÇ  - Pattern matching                             ‚îÇ
‚îÇ  - Known issue detection                        ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Handles 90% of cases ‚Üí Auto-action             ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Escalates 10% to:                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  LLM Agent (smart, expensive)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Complex reasoning                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Novel situations                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Root cause analysis                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Natural language reporting             ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

üí° **Don't use LLM calls for every observation.** Use a rule engine for known patterns, escalate to LLM for novel situations. This cuts costs by 90%.

---

## Practical Example: SRE Agent

```python
class SREAgent:
    def __init__(self):
        self.rules = RuleEngine()
        self.llm = LLMAgent(model="gpt-4o-mini")
        self.memory = StateHistory(window="24h")

    def observe(self):
        """Collect current environment state"""
        return {
            "cpu": prometheus.query("avg(cpu_usage)"),
            "latency_p99": prometheus.query("histogram_quantile(0.99, ...)"),
            "error_rate": prometheus.query("rate(http_errors[5m])"),
            "active_pods": k8s.get_pod_count("production"),
            "recent_deploys": k8s.get_recent_deploys("1h")
        }

    def orient(self, state):
        """Compare to baselines and history"""
        baseline = self.memory.get_baseline(hour=now.hour, day=now.weekday())
        return {
            "cpu_deviation": state["cpu"] / baseline["cpu"],
            "latency_deviation": state["latency_p99"] / baseline["latency_p99"],
            "error_spike": state["error_rate"] > baseline["error_rate"] * 2,
            "recent_change": len(state["recent_deploys"]) > 0
        }

    def decide_and_act(self, state, context):
        """Rule engine first, LLM for complex cases"""
        # Rule-based (fast, cheap)
        action = self.rules.evaluate(state, context)
        if action:
            return self.execute(action)

        # LLM-based (smart, expensive)
        analysis = self.llm.reason(state, context, self.memory)
        if analysis.confidence > 0.8:
            return self.execute(analysis.action)
        else:
            return self.alert_human(analysis)
```

---

## Interview Questions They Will Ask

1. **"How do you design an agent that monitors infrastructure?"**
   ‚Üí OODA loop: observe metrics, orient against baselines, decide action, act. Use rule engine for known patterns, LLM for novel situations. Continuous loop with configurable frequency.

2. **"How do you handle the cost of continuous LLM calls?"**
   ‚Üí Hybrid architecture: rule engine handles 90% of observations (fast, cheap). LLM only invoked for complex, novel situations. Batch observations when possible.

3. **"What's the risk of agents taking automated actions?"**
   ‚Üí Actions can cascade: agent scales up ‚Üí costs spike. Always: reversible actions first, human approval for destructive actions, rollback capability, cost limits.

4. **"How does an environment-aware agent differ from a cron job?"**
   ‚Üí Cron job runs fixed logic on a schedule. An environment-aware agent reasons about context, adapts to conditions, and makes judgment calls. The LLM enables handling novel situations a cron job can't.

5. **"What is the OODA loop?"**
   ‚Üí Observe-Orient-Decide-Act. Military-origin decision loop. Key insight: the Orient phase (contextualizing data) is what makes it effective. Without context, raw data is useless.

---

## Common Mistakes

‚ö†Ô∏è **LLM for every observation** ‚Äî Extremely expensive. Use rules for known patterns, LLM for novelty only.

‚ö†Ô∏è **No feedback loop awareness** ‚Äî Agent's actions change the environment. If it scales up, metrics improve, it may scale down immediately. Account for action lag.

‚ö†Ô∏è **No action safety limits** ‚Äî Agent can scale to 100 replicas or restart services in a loop. Always set action limits and cooldowns.

‚ö†Ô∏è **Stale baselines** ‚Äî Environment-aware agents need up-to-date baselines. A baseline from 6 months ago may not reflect current normal behavior.

‚ö†Ô∏è **No human escalation** ‚Äî Some situations are genuinely novel and dangerous. The agent must know when to escalate instead of acting.

---

## TL;DR

- Environment-aware agents **continuously monitor and react** to their environment
- Core loop: **Observe ‚Üí Orient ‚Üí Decide ‚Üí Act** (OODA)
- Use **hybrid architecture:** rule engine (90%) + LLM (10%) to control costs
- Always have **action safety limits, cooldowns, and human escalation paths**
- Key difference from task agents: **always running, event-driven, context-aware**
