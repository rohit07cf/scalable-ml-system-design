# What Is Agentic AI?

## What It Is

- **Agentic AI** = AI systems that can **plan, reason, act, and self-correct** to achieve goals autonomously
- Unlike GenAI (which produces outputs), Agentic AI drives **outcomes** through multi-step workflows
- An agent = LLM + Tools + Memory + Reasoning Loop
- The key shift: from "answer my question" to "accomplish my objective"

## Why It Matters (Interview Framing)

> "The industry is moving from AI-as-a-tool to AI-as-a-worker. Every major platform â€” Microsoft, Google, OpenAI, Anthropic â€” is investing in agent architectures. Understanding agentic design is now a core interview expectation for AI engineers."

---

## GenAI vs Agentic AI

| Dimension | GenAI (Traditional LLM) | Agentic AI |
|---|---|---|
| **Interaction** | Single turn: prompt â†’ response | Multi-turn: goal â†’ plan â†’ actions â†’ result |
| **Output** | Text, code, images | Completed tasks, decisions, workflows |
| **Memory** | Stateless (per request) | Stateful (short + long-term memory) |
| **Tools** | None (text only) | APIs, code exec, DB, browser, files |
| **Self-correction** | None | Evaluates own output, retries, adapts |
| **Autonomy** | Zero â€” user drives everything | Configurable â€” from co-pilot to autopilot |
| **Architecture** | LLM call | LLM + Orchestrator + Tools + Memory |

ğŸ’¡ **Interview Phrase:** *"GenAI produces outputs. Agentic AI delivers outcomes."*

---

## The Four Pillars of Agentic AI

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     GOAL     â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚PLANNINGâ”‚ â”‚REASONING â”‚ â”‚COLLABORATIONâ”‚
    â”‚        â”‚ â”‚ + ACTING  â”‚ â”‚             â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
              â”‚SELF-EVALUATIONâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Pillar | What It Does |
|---|---|
| **Planning** | Decomposes goal into subtasks, orders them, handles dependencies |
| **Reasoning + Acting** | Thinks step-by-step, calls tools, processes results (ReAct loop) |
| **Collaboration** | Multiple agents work together â€” debate, delegate, verify |
| **Self-Evaluation** | Checks own output quality, retries on failure, learns from mistakes |

---

## The Reasoning + Acting Loop (Core Engine)

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  OBSERVE  â”‚ â† Perceive environment / input
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚  THINK   â”‚ â† Reason about what to do (CoT / ReAct)
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚   ACT    â”‚ â† Call tool / execute action
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚ EVALUATE â”‚ â† Did it work? Is the goal met?
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€â”€ YES â†’ Return result
          â””â”€â”€ NO  â†’ Loop back to OBSERVE
```

ğŸ’¡ **This loop is the heart of every agent pattern.** ReAct, Plan-and-Execute, OODA â€” they're all variations of this.

---

## Simple Mental Model

> Think of Agentic AI like a **junior developer with superpowers:**
> - They receive a task (goal)
> - They break it into steps (planning)
> - They write code, run tests, read docs (tool use)
> - They check if it works (self-evaluation)
> - They ask for help or escalate if stuck (human-in-the-loop)
> - They remember past context (memory)

---

## Practical Example

**Goal:** "Find the top 3 competitors for Acme Corp and create a comparison report"

```
Agent receives goal
  â”‚
  â”œâ”€ PLAN: Decompose into subtasks
  â”‚   â”œâ”€ 1. Search web for Acme Corp competitors
  â”‚   â”œâ”€ 2. For each competitor, gather revenue + product data
  â”‚   â”œâ”€ 3. Compile comparison table
  â”‚   â””â”€ 4. Generate executive summary
  â”‚
  â”œâ”€ ACT: Execute step 1
  â”‚   â””â”€ Tool: web_search("Acme Corp competitors 2025")
  â”‚   â””â”€ Result: [CompA, CompB, CompC, CompD, CompE]
  â”‚
  â”œâ”€ EVALUATE: Too many results â†’ refine to top 3 by market cap
  â”‚
  â”œâ”€ ACT: Execute step 2 (for each of top 3)
  â”‚   â””â”€ Tool: web_search, financial_api
  â”‚
  â”œâ”€ ACT: Execute step 3
  â”‚   â””â”€ Tool: code_interpreter (generate table)
  â”‚
  â”œâ”€ EVALUATE: Check table completeness
  â”‚
  â””â”€ ACT: Execute step 4 â†’ Return report
```

---

## Interview Questions They Will Ask

1. **"What makes an AI system 'agentic' vs just a chatbot?"**
   â†’ Autonomy, tool use, memory, reasoning loops, self-correction

2. **"Explain the difference between GenAI and Agentic AI."**
   â†’ Use the table above. Emphasize output vs outcome.

3. **"What are the risks of giving AI more autonomy?"**
   â†’ Hallucination cascades, uncontrolled tool calls, cost explosion, safety violations

4. **"When would you NOT use an agentic approach?"**
   â†’ Simple Q&A, low-latency requirements, deterministic workflows, cost-sensitive scenarios

5. **"How does an agent decide what to do next?"**
   â†’ Reasoning loop: observe â†’ think â†’ act â†’ evaluate â†’ repeat

---

## Common Mistakes

âš ï¸ **Calling any LLM app "agentic"** â€” If there's no reasoning loop or tool use, it's just a prompt chain

âš ï¸ **Thinking agents are always better** â€” For simple tasks, a single LLM call is faster, cheaper, and more reliable

âš ï¸ **Ignoring cost** â€” Each reasoning step = more tokens = more money. A 10-step agent costs 10x a single call

âš ï¸ **No human-in-the-loop** â€” Production agents need escape hatches and approval gates

âš ï¸ **Conflating "agent" with "autonomous"** â€” Agents exist on a spectrum from co-pilot to fully autonomous

---

## TL;DR

- **Agentic AI** = LLM + Tools + Memory + Reasoning Loop â†’ achieves goals autonomously
- Core loop: **Observe â†’ Think â†’ Act â†’ Evaluate â†’ Repeat**
- GenAI = outputs, Agentic AI = **outcomes**
- Four pillars: **Planning, Reasoning+Acting, Collaboration, Self-Evaluation**
- Always consider: **cost, latency, safety, and when NOT to use agents**

---

*Next: [01_core_concepts/reasoning_loops.md](../01_core_concepts/reasoning_loops.md) â†’*
