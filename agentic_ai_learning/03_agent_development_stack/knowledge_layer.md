# Knowledge Layer

## What It Is

- The **external knowledge infrastructure** that gives agents access to information beyond the LLM's training data
- Core pattern: **RAG** (Retrieval-Augmented Generation) ‚Äî retrieve relevant docs, inject into prompt
- Includes vector databases, knowledge graphs, and hybrid retrieval systems
- This is how agents answer questions about YOUR data, not just the internet

## Why It Matters (Interview Framing)

> "RAG is the most deployed AI pattern in production today. Interviewers will absolutely ask about chunking strategies, embedding models, reranking, and when to use a knowledge graph vs a vector DB. This is bread-and-butter for AI engineers."

---

## Knowledge Layer Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  AGENT                            ‚îÇ
‚îÇ  "What's our refund policy for enterprise?"       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ              KNOWLEDGE LAYER                      ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  QUERY   ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ RETRIEVE ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ   RERANK     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (embed)  ‚îÇ   ‚îÇ (top-K)  ‚îÇ   ‚îÇ (score/filter)‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                       ‚îÇ          ‚îÇ
‚îÇ  Data Sources:                        ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇVector DB ‚îÇ ‚îÇKnowledge ‚îÇ   ‚îÇ  AUGMENT     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ(Pinecone ‚îÇ ‚îÇ  Graph   ‚îÇ   ‚îÇ (inject into ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Weaviate ‚îÇ ‚îÇ (Neo4j)  ‚îÇ   ‚îÇ  LLM prompt) ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Chroma)  ‚îÇ ‚îÇ          ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ            INGESTION PIPELINE                     ‚îÇ
‚îÇ  Docs ‚Üí Chunk ‚Üí Embed ‚Üí Store                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## RAG (Retrieval-Augmented Generation)

### The RAG Pipeline

```
1. INGEST (offline)
   Documents ‚Üí Chunker ‚Üí Embedding Model ‚Üí Vector DB

2. QUERY (online)
   User Query ‚Üí Embed ‚Üí Similarity Search ‚Üí Top-K Chunks ‚Üí LLM Prompt ‚Üí Answer
```

### Chunking Strategies

| Strategy | How | Best For |
|---|---|---|
| **Fixed-size** | Split every N characters/tokens | Simple, fast, baseline |
| **Sentence-based** | Split on sentence boundaries | Natural text |
| **Paragraph-based** | Split on paragraph boundaries | Structured documents |
| **Semantic** | Split where topic changes (via embeddings) | Mixed-content docs |
| **Recursive** | Try largest split, recurse if too big | Code, markdown, HTML |
| **Document-aware** | Respect headers, sections, tables | Technical documentation |

üí° **Chunk size matters more than embedding model choice.** Too small = no context. Too large = noise. Start with 512-1024 tokens.

### Embedding Models

| Model | Dimensions | Speed | Quality | Cost |
|---|---|---|---|---|
| **OpenAI text-embedding-3-large** | 3072 | Fast (API) | High | $$$ |
| **OpenAI text-embedding-3-small** | 1536 | Fast (API) | Good | $$ |
| **Cohere embed-v3** | 1024 | Fast (API) | High | $$ |
| **BGE-large** | 1024 | Self-host | High | Free |
| **E5-large-v2** | 1024 | Self-host | Good | Free |

---

## Vector Databases

| Vector DB | Type | Strengths | Best For |
|---|---|---|---|
| **Pinecone** | Managed | Easiest to use, auto-scaling | Startups, fast prototyping |
| **Weaviate** | Managed/Self-host | Hybrid search, GraphQL API | Production, hybrid needs |
| **Chroma** | Embedded | Lightweight, easy local dev | Prototyping, small datasets |
| **Qdrant** | Managed/Self-host | Fast, Rust-based, filtering | Performance-critical |
| **pgvector** | PostgreSQL extension | Use existing Postgres | Teams already on Postgres |
| **Milvus** | Self-host | Billion-scale vectors | Large-scale production |

---

## Graph RAG

```
Traditional RAG:          Graph RAG:

Query ‚Üí Vector Search     Query ‚Üí Vector Search
     ‚Üí Chunks                  ‚Üí Entities + Relationships
     ‚Üí LLM                     ‚Üí Subgraph
                                ‚Üí LLM

"What's the refund         "What's the refund policy?"
 policy?"                   ‚Üí Entity: RefundPolicy
‚Üí Chunk: "...refund..."     ‚Üí Related: EnterpriseCustomer
                            ‚Üí Related: 30DayWindow
                            ‚Üí Related: ApprovalProcess
                            ‚Üí Richer, structured context
```

**When Graph RAG > Vector RAG:**
- Data has rich relationships (org charts, product catalogs, compliance rules)
- Questions require multi-hop reasoning ("Who approved the policy that applies to enterprise customers?")
- Entities and their relationships matter more than text similarity

**When Vector RAG is sufficient:**
- Simple Q&A over documents
- Text-heavy content (articles, support docs, manuals)
- No complex relationships between entities

---

## Knowledge Graphs

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    HAS_POLICY    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Enterprise ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ RefundPolicy  ‚îÇ
‚îÇ  Customer   ‚îÇ                  ‚îÇ (30 days)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                  REQUIRES
                                        ‚îÇ
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ  VP Approval  ‚îÇ
                                 ‚îÇ  (> $10K)     ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- **Storage:** Neo4j, Amazon Neptune, ArangoDB
- **Query language:** Cypher (Neo4j), SPARQL, Gremlin
- **Strength:** Multi-hop queries, relationship traversal
- **Challenge:** Building and maintaining the graph

---

## Advanced RAG Patterns

| Pattern | Description | When to Use |
|---|---|---|
| **Naive RAG** | Simple embed ‚Üí search ‚Üí generate | MVP, prototype |
| **Sentence Window** | Retrieve sentence + surrounding context | Better context |
| **Parent-Child** | Retrieve child chunk, inject parent chunk | Hierarchical docs |
| **Hybrid Search** | Vector search + keyword search (BM25) | Mixed query types |
| **Reranking** | Retrieve top-50, rerank to top-5 with cross-encoder | Quality-critical |
| **Query Expansion** | Generate multiple query variants, merge results | Recall improvement |
| **Self-RAG** | Agent decides when to retrieve vs use existing context | Token efficiency |

---

## Practical Example: Enterprise Knowledge Stack

```python
# Knowledge layer configuration
knowledge_config = {
    "vector_db": {
        "provider": "pinecone",
        "index": "company-docs",
        "embedding_model": "text-embedding-3-small",
        "chunk_size": 512,
        "chunk_overlap": 50
    },
    "knowledge_graph": {
        "provider": "neo4j",
        "database": "company-ontology",
        "use_for": ["org_structure", "policy_relations", "product_catalog"]
    },
    "retrieval": {
        "strategy": "hybrid",           # Vector + BM25
        "top_k": 20,                    # Initial retrieval
        "rerank_to": 5,                 # After reranking
        "reranker": "cohere-rerank-v3"
    }
}
```

---

## Interview Questions They Will Ask

1. **"Walk me through a RAG pipeline."**
   ‚Üí Ingest: docs ‚Üí chunk ‚Üí embed ‚Üí store in vector DB. Query: embed query ‚Üí similarity search ‚Üí top-K chunks ‚Üí inject into LLM prompt ‚Üí generate answer.

2. **"How do you choose chunk size?"**
   ‚Üí Depends on content type and model. Start 512-1024 tokens. Too small = lost context. Too large = noise + cost. Benchmark with your actual queries.

3. **"When would you use a knowledge graph vs a vector DB?"**
   ‚Üí Vector DB: text similarity, simple Q&A. Knowledge graph: relationship queries, multi-hop reasoning, structured entities. Best systems use both (Graph RAG).

4. **"How do you improve RAG quality?"**
   ‚Üí Hybrid search (vector + BM25), reranking, better chunking, query expansion, metadata filtering, evaluation with ground-truth Q&A pairs.

5. **"What is Graph RAG?"**
   ‚Üí Combine vector retrieval with knowledge graph traversal. Retrieve entities and their relationships, not just text chunks. Better for complex, multi-hop queries.

---

## Common Mistakes

‚ö†Ô∏è **Skipping reranking** ‚Äî Top-K from vector search alone often includes irrelevant results. Reranking with a cross-encoder dramatically improves precision.

‚ö†Ô∏è **One chunk size for all content** ‚Äî Code, tables, and prose need different chunking strategies. Use document-aware chunking.

‚ö†Ô∏è **Not evaluating retrieval quality** ‚Äî If you don't measure precision@k and recall@k, you're guessing. Build a test set of query-document pairs.

‚ö†Ô∏è **Ignoring metadata filtering** ‚Äî Don't just search by semantic similarity. Filter by date, document type, department, access level.

‚ö†Ô∏è **Using RAG when the answer is in the prompt** ‚Äî Self-RAG: let the agent decide whether to retrieve or use existing context. Saves latency and cost.

---

## TL;DR

- **RAG** = retrieve relevant docs, inject into LLM prompt (most common pattern)
- Key decisions: **chunk size, embedding model, vector DB, retrieval strategy**
- Use **hybrid search** (vector + BM25) + **reranking** for production quality
- **Graph RAG** for relationship-heavy, multi-hop queries
- Always **evaluate retrieval quality** with ground-truth test sets
