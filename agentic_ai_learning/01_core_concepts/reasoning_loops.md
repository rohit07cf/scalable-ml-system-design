# Reasoning Loops

## What It Is

- The **iterative thought process** an agent uses to decide its next action
- Each loop cycle: perceive â†’ reason â†’ act â†’ observe result â†’ reason again
- Different loop types optimize for different trade-offs (speed vs thoroughness)
- This is what separates an "agent" from a "prompt chain"

## Why It Matters (Interview Framing)

> "The reasoning loop is the **control flow** of an agent. Choosing the right loop pattern determines whether your agent is fast-but-shallow or thorough-but-expensive. Interviewers test if you can articulate these trade-offs."

---

## The Five Reasoning Loop Patterns

### 1. ReAct (Reasoning + Acting)

```
Thought: I need to find the user's order status
Action: call_api(order_service, GET /orders/123)
Observation: {status: "shipped", eta: "2025-03-15"}
Thought: I have the info, I can respond now
Action: respond("Your order shipped, arriving March 15")
```

- **How it works:** Interleave reasoning (Thought) with actions (tool calls)
- **Strength:** Grounded â€” every thought leads to a verifiable action
- **Weakness:** Sequential; can't explore multiple paths
- **When to use:** Most general-purpose agent tasks

ğŸ’¡ **This is the default pattern. If in doubt, use ReAct.**

---

### 2. Chain-of-Thought (CoT)

```
Question: What's 23 Ã— 47?
Thought: 23 Ã— 47 = 23 Ã— 40 + 23 Ã— 7 = 920 + 161 = 1081
Answer: 1081
```

- **How it works:** LLM "shows its work" before answering
- **Strength:** Improves accuracy on reasoning-heavy tasks
- **Weakness:** No external actions â€” purely internal reasoning
- **When to use:** Math, logic, multi-step reasoning without tool needs

âš ï¸ CoT alone doesn't make an agent. It's a **reasoning technique**, not an agent pattern.

---

### 3. Tree-of-Thought (ToT)

```
            â”Œâ”€ Path A: Use SQL query    â†’ Score: 0.7
  Problem â”€â”€â”¤
            â”œâ”€ Path B: Use API endpoint â†’ Score: 0.9  â† Selected
            â”‚
            â””â”€ Path C: Use cached data  â†’ Score: 0.4
```

- **How it works:** Explore multiple reasoning paths, evaluate each, pick the best
- **Strength:** Better for problems with multiple valid approaches
- **Weakness:** Expensive â€” requires multiple LLM calls per step
- **When to use:** Complex planning, code generation, creative problem solving

---

### 4. OODA Loop (Observe-Orient-Decide-Act)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ OBSERVE  â”‚â”€â”€â”€â–¶â”‚  ORIENT  â”‚â”€â”€â”€â–¶â”‚  DECIDE  â”‚â”€â”€â”€â–¶â”‚ ACT  â”‚
â”‚ (data in)â”‚    â”‚(context) â”‚    â”‚ (choose) â”‚    â”‚(exec)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
     â–²                                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **How it works:** Military-inspired loop emphasizing **context awareness** (Orient phase)
- **Strength:** Excellent for dynamic, changing environments
- **Weakness:** Adds overhead for simple tasks
- **When to use:** Real-time monitoring agents, trading agents, security agents

---

### 5. Self-Correction Loops

```
Generate answer
    â”‚
    â–¼
Critique own answer  â† "Is this correct? Complete? Safe?"
    â”‚
    â”œâ”€â”€ PASS â†’ Return answer
    â””â”€â”€ FAIL â†’ Regenerate with critique as feedback
                    â”‚
                    â–¼
               Re-critique â†’ (max 3 iterations)
```

- **How it works:** Agent generates, then reviews its own output
- **Strength:** Catches hallucinations and incomplete answers
- **Weakness:** Can loop forever without a max iteration limit
- **When to use:** High-stakes outputs (code, financial analysis, medical)

âš ï¸ **Always set a max iteration count.** Unbounded self-correction = infinite cost.

---

## Comparison Table

| Pattern | # LLM Calls | Tool Use | Best For | Cost |
|---|---|---|---|---|
| **ReAct** | Medium (sequential) | Yes | General agent tasks | Medium |
| **CoT** | 1 | No | Reasoning-only tasks | Low |
| **ToT** | High (branching) | Optional | Complex planning | High |
| **OODA** | Medium | Yes | Dynamic environments | Medium |
| **Self-Correction** | 2-4x base | Optional | High-stakes output | Medium-High |

---

## Architecture Diagram: How Loops Fit in an Agent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENT                   â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     REASONING LOOP          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚Thinkâ”‚â†’â”‚Act â”‚â†’â”‚Evaluateâ”‚â”€â”€â”¤    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚     â–²                  â”‚    â”‚    â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚          â”‚                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”           â”‚
â”‚    â”‚ MEMORY â”‚ â”‚ TOOLS  â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Practical Example: Customer Support Agent

```python
# ReAct loop pseudocode
while not goal_achieved and iterations < MAX_ITER:
    thought = llm.reason(context + memory + last_observation)

    if thought.is_final_answer:
        return thought.answer

    action = thought.next_action          # e.g., "search_kb"
    observation = tools.execute(action)   # e.g., KB article content

    memory.add(thought, action, observation)
    iterations += 1
```

---

## Interview Questions They Will Ask

1. **"Explain the ReAct pattern."**
   â†’ Interleaved reasoning and acting. Thought â†’ Action â†’ Observation â†’ repeat.

2. **"When would you use Tree-of-Thought over Chain-of-Thought?"**
   â†’ When multiple valid solution paths exist and you need to evaluate trade-offs.

3. **"How do you prevent infinite loops in self-correction?"**
   â†’ Max iteration limits, diminishing improvement detection, timeout budgets.

4. **"What's the cost implication of different reasoning loops?"**
   â†’ CoT = 1 call. ReAct = N calls (N = steps). ToT = branching factor Ã— depth calls.

5. **"How do you choose which reasoning loop to use?"**
   â†’ Simple reasoning â†’ CoT. Tool-using tasks â†’ ReAct. Complex planning â†’ ToT. Dynamic env â†’ OODA.

---

## Common Mistakes

âš ï¸ **Using ToT for simple tasks** â€” Massive overkill. Most tasks work fine with ReAct.

âš ï¸ **No iteration limits** â€” Every loop MUST have a max iteration count and token budget.

âš ï¸ **Confusing CoT with ReAct** â€” CoT has no actions/tools. ReAct interleaves thinking WITH doing.

âš ï¸ **Not logging loop iterations** â€” You need observability into each step for debugging.

âš ï¸ **Ignoring cost** â€” A 15-step ReAct loop with GPT-4o â‰ˆ $0.50-2.00 per request.

---

## TL;DR

- **ReAct** = default agent loop (Thought â†’ Action â†’ Observation)
- **CoT** = reasoning-only, no tools (good for math/logic)
- **ToT** = explore multiple paths, pick best (expensive but thorough)
- **OODA** = context-aware loop for dynamic environments
- **Always set max iterations and token budgets** to prevent runaway costs
