# Memory Systems

## What It Is

- **Memory** gives agents the ability to retain and recall information across reasoning steps and sessions
- Without memory, every LLM call starts from zero â€” no context, no learning
- Memory is what makes an agent feel "intelligent" vs "amnesic"
- Four types: short-term, long-term, vector (RAG), and workspace memory

## Why It Matters (Interview Framing)

> "Memory design is a top interview differentiator. Everyone can build a ReAct loop. The hard part is: how does your agent remember what it did 5 steps ago? How does it learn across sessions? That's where memory architecture matters."

---

## Simple Mental Model

> **Short-term memory** = your whiteboard during a meeting
> **Long-term memory** = your personal notes app
> **Vector memory** = your company's search engine
> **Workspace memory** = the files open on your desktop right now

---

## The Four Memory Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT MEMORY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SHORT-TERM  â”‚  LONG-TERM   â”‚   VECTOR   â”‚  WORKSPACE  â”‚
â”‚  (Working)   â”‚  (Semantic)  â”‚   (RAG)    â”‚  (Session)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Current task â”‚ Past sessionsâ”‚ Knowledge  â”‚ Files, code â”‚
â”‚ context      â”‚ User prefs   â”‚ base docs  â”‚ artifacts   â”‚
â”‚              â”‚ Learned factsâ”‚ Embeddings â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ In-context   â”‚ External DB  â”‚ Vector DB  â”‚ File system â”‚
â”‚ (prompt)     â”‚ (Redis/PG)   â”‚(Pinecone)  â”‚ (local/S3)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Volatile     â”‚ Persistent   â”‚ Persistent â”‚ Session-    â”‚
â”‚              â”‚              â”‚            â”‚ scoped      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1. Short-Term Memory (Working Memory)

**What:** The conversation history and scratchpad within the current agent execution.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LLM Context Window         â”‚
â”‚                                 â”‚
â”‚  System prompt                  â”‚
â”‚  + User goal                    â”‚
â”‚  + Step 1: Thought + Action     â”‚
â”‚  + Step 1: Observation          â”‚
â”‚  + Step 2: Thought + Action     â”‚  â† THIS is short-term memory
â”‚  + Step 2: Observation          â”‚
â”‚  + Step 3: Thought + ...        â”‚
â”‚                                 â”‚
â”‚  [TOKEN LIMIT]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Storage:** In the LLM's context window (prompt)
- **Lifetime:** Current execution only
- **Limit:** Token window (4Kâ€“200K depending on model)
- **Challenge:** Context window overflow on long tasks

**Solutions for overflow:**
- Sliding window (drop oldest messages)
- Summarization (compress old steps into summary)
- Hierarchical (keep summary + last N steps)

---

### 2. Long-Term Memory (Semantic Memory)

**What:** Persistent facts, user preferences, and learned information across sessions.

```
Agent Session 1:            Agent Session 2:
  "User prefers Python"  â†’   Retrieve: "User prefers Python"
  Save to long-term DB       Use in response
```

- **Storage:** External database (Redis, PostgreSQL, DynamoDB)
- **Lifetime:** Permanent (or TTL-based)
- **Access:** Queried at start of session or on-demand
- **Format:** Key-value, structured JSON, or natural language

**Example schema:**
```json
{
  "user_id": "u_123",
  "memories": [
    {"fact": "Prefers Python over JS", "confidence": 0.9, "created": "2025-01-15"},
    {"fact": "Works at Acme Corp, ML team", "confidence": 0.95, "created": "2025-02-01"},
    {"fact": "Timezone: PST", "confidence": 1.0, "created": "2025-02-01"}
  ]
}
```

---

### 3. Vector Memory (RAG)

**What:** External knowledge retrieved via semantic similarity search.

```
Query: "How to configure SSL?"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embed    â”‚â”€â”€â”€â”€â–¶â”‚  Vector DB     â”‚â”€â”€â”€â”€â–¶â”‚ Top-K    â”‚
â”‚ query    â”‚     â”‚  (similarity   â”‚     â”‚ results  â”‚
â”‚          â”‚     â”‚   search)      â”‚     â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                    Inject into LLM prompt
```

- **Storage:** Vector database (Pinecone, Weaviate, Chroma, Qdrant)
- **Content:** Company docs, knowledge base, past conversations
- **Access:** Semantic search (not keyword match)
- **Key metric:** Retrieval relevance (precision@k, recall@k)

ğŸ’¡ **RAG is the most common memory pattern in production agents.**

---

### 4. Workspace Memory

**What:** Files, artifacts, and intermediate outputs created during the current task.

- Code files being edited
- Reports being drafted
- Data files being analyzed
- Scratchpad notes

- **Storage:** Local filesystem, S3, temp directory
- **Lifetime:** Session-scoped (cleaned up after task completion)
- **Access:** File read/write tools

---

## Choosing Memory Types

| Scenario | Memory Type |
|---|---|
| Agent needs context from 3 steps ago | **Short-term** (in-context) |
| Remember user prefers dark mode | **Long-term** (persistent DB) |
| Look up company HR policy | **Vector** (RAG) |
| Edit a code file across multiple steps | **Workspace** |
| Agent needs to recall what failed yesterday | **Long-term** |
| Search through 10,000 support tickets | **Vector** |

---

## Practical Example: Customer Support Agent Memory

```python
class AgentMemory:
    def __init__(self, user_id):
        # Short-term: conversation buffer
        self.conversation = []

        # Long-term: load user profile
        self.user_profile = redis.get(f"user:{user_id}:memory")

        # Vector: connect to knowledge base
        self.kb = PineconeIndex("support-docs")

        # Workspace: temp files for this session
        self.workspace = TempDirectory()

    def get_context(self, query):
        """Build context for LLM from all memory types"""
        return {
            "conversation": self.conversation[-10:],     # Last 10 turns
            "user_facts": self.user_profile.facts,       # Known preferences
            "relevant_docs": self.kb.search(query, k=3), # Top 3 KB articles
            "workspace_files": self.workspace.list()      # Current artifacts
        }
```

---

## Interview Questions They Will Ask

1. **"How do you handle context window limits in a long-running agent?"**
   â†’ Sliding window, summarization, hierarchical memory. Move older context to external storage, keep summaries in-context.

2. **"Explain the difference between short-term and long-term memory in agents."**
   â†’ Short-term = in-context (prompt), volatile, limited by token window. Long-term = external DB, persistent, unlimited.

3. **"How does RAG fit into agent memory?"**
   â†’ RAG is vector memory â€” external knowledge retrieved by semantic similarity. It's how agents access large knowledge bases without stuffing everything into the prompt.

4. **"How would you implement memory for a multi-session agent?"**
   â†’ Long-term memory in a persistent store. Save key facts, user preferences, and task outcomes. Load at session start.

5. **"What happens when the context window fills up?"**
   â†’ Oldest messages are dropped or summarized. Critical info should be persisted to long-term memory before eviction.

---

## Common Mistakes

âš ï¸ **Stuffing everything into the prompt** â€” Context windows are limited and expensive. Use external memory for large datasets.

âš ï¸ **No memory eviction strategy** â€” Without summarization or sliding window, the agent hits token limits and crashes.

âš ï¸ **Treating RAG as "done"** â€” Retrieval quality directly impacts agent quality. Bad retrieval = bad answers. Tune chunk size, embedding model, reranking.

âš ï¸ **Not persisting important facts** â€” If the agent learns something important, save it to long-term memory. Don't rely on the conversation buffer.

âš ï¸ **Ignoring memory in multi-agent systems** â€” Agents sharing memory need coordination. Race conditions, stale reads, and conflicting updates are real.

---

## TL;DR

- **Short-term** = conversation context in the prompt (volatile, token-limited)
- **Long-term** = persistent facts in external DB (Redis, PostgreSQL)
- **Vector (RAG)** = semantic search over knowledge base (Pinecone, Weaviate)
- **Workspace** = files and artifacts for the current session
- **Key challenge:** context window overflow â†’ solve with summarization + external storage
